{"name":"Wells-fargo-analytics-comp","tagline":"","body":"# Topics\r\n## Introduction\r\n\r\n\r\n\r\n## Approach and Methodology\r\n\r\nOur team has gathered all the tweets from August 2015, and Facebook comments between Aug. 2014 and Aug. 2015 regarding the chosen banks across the industry from the data file given, and first analyzed its vocabulary frequency, 3,000 counts being the least amount of frequency. This process helped us to understand the general comments that were being said about the bank industry, including the ones involving four main banks. We also approached these tweets and Facebook comments by excerpting those which only involve our four main banks. We first split the tweets and comments by Bank A, B, C, D, trying to grasp the level of negativeness and positiveness of each bank by using the sentiment scoring algorithm which would provide a score for each tweets and comments between -10 and 10 with 0 being neutral. The tweets and Facebook comments that were split at the previous stage contained all different kinds of topics that were not financially related. Therefore, we now wanted to pick out tweets and comments that only take financial terms into account among them to comprehend how positively or negatively each bank was perceived by customers. We then used the same sentiment scoring algorithm method again on those financial related tweets and comments to score each bank according to the score on each tweets and comments. \r\n\r\n## Graphics\r\n\r\nWord Frequency Chart Entire Data Set (min count 3000)\r\n![](http://imgur.com/FswUfrL)\r\n\r\nBank D sentiment scores for the word 'account'\r\n![](http://imgur.com/mpRNZ0j)\r\n\r\nMore charts like the one above were done for the overall sentiment score of each bank, and for each of our chosen words (account, finance, credit, and service) for each bank for a total of 16.\r\n\r\n## Code\r\n\r\n### Python Code\r\n\r\n```P\r\n# coded by: Joshua Turner\r\n\r\ndef main():\r\n    banksort()\r\n    accountsort()\r\n    creditsort()\r\n    financesort()\r\n    servicesort()\r\n\r\ndef banksort():\r\n    \"\"\"\r\n    This function reads the contents of a text file, scans for BankA,B,C,D,\r\n    and writes the list item to the appropriate output\r\n    file. \r\n    \"\"\"\r\n    infileName = \"DataSet.txt\"\r\n    infile = open(infileName, \"rb\")\r\n    bankAoutfile = \"bankA.txt\"\r\n    bankBoutfile = \"bankB.txt\"\r\n    bankCoutfile = \"bankC.txt\"\r\n    bankDoutfile = \"bankD.txt\"\r\n    outfileA = open(bankAoutfile, \"w\")\r\n    outfileB = open(bankBoutfile, \"w\")\r\n    outfileC = open(bankCoutfile, \"w\")\r\n    outfileD = open(bankDoutfile, \"w\")    \r\n    for line in infile:\r\n        if b\"BankA\" in line:\r\n            print(line, file=outfileA)\r\n        elif b\"BankB\" in line:\r\n            print(line, file=outfileB)\r\n        elif b\"BankC\" in line:\r\n            print(line, file=outfileC)\r\n        elif b\"BankD\" in line:\r\n            print(line, file=outfileD)\r\n\r\n    infile.close()\r\n    outfileA.close()\r\n    outfileB.close()\r\n    outfileC.close()\r\n    outfileD.close()\r\n\r\ndef accountsort():\r\n    \"\"\"\r\n    This function reads the contents of the sorted bank files (A,B,C,D), scans\r\n    for the word 'account' and writes to the appropriate output file.\r\n    \"\"\"\r\n    infileA = open(\"bankA.txt\", \"rb\")\r\n    infileB = open(\"bankB.txt\", \"rb\")\r\n    infileC = open(\"bankC.txt\", \"rb\")\r\n    infileD = open(\"bankD.txt\", \"rb\")\r\n    accountoutA = open(\"accountA.txt\", \"w\")\r\n    accountoutB = open(\"accountB.txt\", \"w\")\r\n    accountoutC = open(\"accountC.txt\", \"w\")\r\n    accountoutD = open(\"accountD.txt\", \"w\")\r\n    for line in infileA:\r\n        if b\"account\" in line:\r\n            print(line, file=accountoutA)\r\n    for line in infileB:\r\n        if b\"account\" in line:\r\n            print(line, file=accountoutB)\r\n    for line in infileC:\r\n        if b\"account\" in line:\r\n            print(line, file=accountoutC)\r\n    for line in infileD:\r\n        if b\"account\" in line:\r\n            print(line, file=accountoutD)\r\n\r\n    infileA.close()\r\n    infileB.close()\r\n    infileC.close()\r\n    infileD.close()\r\n    accountoutA.close()\r\n    accountoutB.close()\r\n    accountoutC.close()\r\n    accountoutD.close()\r\n\r\ndef creditsort():\r\n    \"\"\"\r\n    This function reads the contents of the sorted bank files (A,B,C,D), scans\r\n    for the word 'credit' and writes to the appropriate output file.\r\n    \"\"\"\r\n    infileA = open(\"bankA.txt\", \"rb\")\r\n    infileB = open(\"bankB.txt\", \"rb\")\r\n    infileC = open(\"bankC.txt\", \"rb\")\r\n    infileD = open(\"bankD.txt\", \"rb\")\r\n    creditoutA = open(\"creditA.txt\", \"w\")\r\n    creditoutB = open(\"creditB.txt\", \"w\")\r\n    creditoutC = open(\"creditC.txt\", \"w\")\r\n    creditoutD = open(\"creditD.txt\", \"w\")\r\n    for line in infileA:\r\n        if b\"credit\" in line:\r\n            print(line, file=creditoutA)\r\n    for line in infileB:\r\n        if b\"credit\" in line:\r\n            print(line, file=creditoutB)\r\n    for line in infileC:\r\n        if b\"credit\" in line:\r\n            print(line, file=creditoutC)\r\n    for line in infileD:\r\n        if b\"credit\" in line:\r\n            print(line, file=creditoutD)\r\n\r\n    infileA.close()\r\n    infileB.close()\r\n    infileC.close()\r\n    infileD.close()\r\n    creditoutA.close()\r\n    creditoutB.close()\r\n    creditoutC.close()\r\n    creditoutD.close()\r\n\r\ndef financesort():\r\n    \"\"\"\r\n    This function reads the contents of the sorted bank files (A,B,C,D), scans\r\n    for the word 'finance' and writes to the appropriate output file.\r\n    \"\"\"\r\n    infileA = open(\"bankA.txt\", \"rb\")\r\n    infileB = open(\"bankB.txt\", \"rb\")\r\n    infileC = open(\"bankC.txt\", \"rb\")\r\n    infileD = open(\"bankD.txt\", \"rb\")\r\n    financeoutA = open(\"financeA.txt\", \"w\")\r\n    financeoutB = open(\"financeB.txt\", \"w\")\r\n    financeoutC = open(\"financeC.txt\", \"w\")\r\n    financeoutD = open(\"financeD.txt\", \"w\")\r\n    for line in infileA:\r\n        if b\"finance\" in line:\r\n            print(line, file=financeoutA)\r\n    for line in infileB:\r\n        if b\"finance\" in line:\r\n            print(line, file=financeoutB)\r\n    for line in infileC:\r\n        if b\"finance\" in line:\r\n            print(line, file=financeoutC)\r\n    for line in infileD:\r\n        if b\"finance\" in line:\r\n            print(line, file=financeoutD)\r\n\r\n    infileA.close()\r\n    infileB.close()\r\n    infileC.close()\r\n    infileD.close()\r\n    financeoutA.close()\r\n    financeoutB.close()\r\n    financeoutC.close()\r\n    financeoutD.close()\r\n\r\ndef servicesort():\r\n    \"\"\"\r\n    This function reads the contents of the sorted bank files (A,B,C,D), scans\r\n    for the word 'service' and writes to the appropriate output file.\r\n    \"\"\"\r\n    infileA = open(\"bankA.txt\", \"rb\")\r\n    infileB = open(\"bankB.txt\", \"rb\")\r\n    infileC = open(\"bankC.txt\", \"rb\")\r\n    infileD = open(\"bankD.txt\", \"rb\")\r\n    serviceoutA = open(\"serviceA.txt\", \"w\")\r\n    serviceoutB = open(\"serviceB.txt\", \"w\")\r\n    serviceoutC = open(\"serviceC.txt\", \"w\")\r\n    serviceoutD = open(\"serviceD.txt\", \"w\")\r\n    for line in infileA:\r\n        if b\"service\" in line:\r\n            print(line, file=serviceoutA)\r\n    for line in infileB:\r\n        if b\"service\" in line:\r\n            print(line, file=serviceoutB)\r\n    for line in infileC:\r\n        if b\"service\" in line:\r\n            print(line, file=serviceoutC)\r\n    for line in infileD:\r\n        if b\"service\" in line:\r\n            print(line, file=serviceoutD)\r\n\r\n    infileA.close()\r\n    infileB.close()\r\n    infileC.close()\r\n    infileD.close()\r\n    serviceoutA.close()\r\n    serviceoutB.close()\r\n    serviceoutC.close()\r\n    serviceoutD.close()\r\n       \r\nmain()\r\n```\r\n### R Code\r\n\r\n```R\r\n## Well's Fargo FB/Twitter data competition\r\n## reference: https://rstudio-pubs-static.s3.amazonaws.com/31867_8236987cf0a8444e962ccd2aec46d9c3.html\r\n## reference: http://www.inside-r.org/howto/mining-twitter-airline-consumer-sentiment\r\n## coded by: Joshua Turner \r\n\r\nlibrary(plyr)\r\nlibrary(stringr)\r\nlibrary(ggplot2)\r\nlibrary(tm)\r\nlibrary(rpart)\r\n\r\n# Hu and Liu's \"opinion lexicon,\" categorizes words as positive or negative\r\n# found at http://www.cs.uic.edu/~liub/FBS/opinion-lexicon-English.rar\r\nhu.liu.pos = scan('~/positive-words.txt',\r\n                  what='character', comment.char=';')\r\nhu.liu.neg = scan('~/negative-words.txt',\r\n                  what='character', comment.char=';')\r\npos.words = c(hu.liu.pos, 'upgrade')\r\nneg.words = c(hu.liu.neg, 'wtf', 'wait', 'waiting',\r\n              'epicfail', 'mechanical')\r\n# score.sentiment() function uses laply() to iterate through the input text. \r\n# It strips punctuation and control characters from each line using Râ€™s regular \r\n# expression-powered substitution function, gsub(), and uses match() against \r\n# each word list to find matches; taken from\r\n# http://www.inside-r.org/howto/mining-twitter-airline-consumer-sentiment\r\nscore.sentiment = function(sentences, pos.words, neg.words, .progress='none')\r\n{\r\n  require(plyr)\r\n  require(stringr)\r\n  \r\n  # we got a vector of sentences. plyr will handle a list\r\n  # or a vector as an \"l\" for us\r\n  # we want a simple array of scores back, so we use\r\n  # \"l\" + \"a\" + \"ply\" = \"laply\":\r\n  scores = laply(sentences, function(sentence, pos.words, neg.words) {\r\n    \r\n    # clean up sentences with R's regex-driven global substitute, gsub():\r\n    sentence = gsub('[[:punct:]]', '', sentence)\r\n    sentence = gsub('[[:cntrl:]]', '', sentence)\r\n    sentence = gsub('\\\\d+', '', sentence)\r\n    # and convert to lower case:\r\n    sentence = tolower(sentence)\r\n    \r\n    # split into words. str_split is in the stringr package\r\n    word.list = str_split(sentence, '\\\\s+')\r\n    # sometimes a list() is one level of hierarchy too much\r\n    words = unlist(word.list)\r\n    \r\n    # compare our words to the dictionaries of positive & negative terms\r\n    pos.matches = match(words, pos.words)\r\n    neg.matches = match(words, neg.words)\r\n    \r\n    # match() returns the position of the matched term or NA\r\n    # we just want a TRUE/FALSE:\r\n    pos.matches = !is.na(pos.matches)\r\n    neg.matches = !is.na(neg.matches)\r\n    \r\n    # and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():\r\n    score = sum(pos.matches) - sum(neg.matches)\r\n    \r\n    return(score)\r\n  }, pos.words, neg.words, .progress=.progress )\r\n  \r\n  scores.df = data.frame(score=scores, text=sentences)\r\n  return(scores.df)\r\n}\r\n\r\n\r\n# used to get entire data set\r\ncname <- \"~/BankDataSet\"\r\ncname   \r\ndir(cname)\r\n\r\n# creates a subset of 10000 to work\r\nsetwd(\"~/BankDataSet\")\r\ndf = read.csv(\"DataSet.txt\")\r\nidx.10000 = sample(1:nrow(df), 10000)\r\ndf.10000 = df[idx.10000,]\r\ndf.entire = df\r\ndf = df.10000\r\ndocs <- Corpus(DirSource(cname))\r\n\r\n# finds sentiment score for whole data set\r\nbank.scores = score.sentiment(df, pos.words,\r\n                              neg.words, .progress='text')\r\n# formats data for word frequency count\r\nsummary(docs)\r\ndocs <- tm_map(docs, removePunctuation)\r\ndocs <- tm_map(docs, removeWords, stopwords(\"english\"))\r\ndocs <- tm_map(docs, removeWords, c(\"Name\", \"ADDRESS\", \"PHONE\", \"INTERNET\", \"twit_hndl\", \"get\", \"got\",\"let\",\"number\"))\r\ndocs <- tm_map(docs, PlainTextDocument)   \r\ndtm <- DocumentTermMatrix(docs)   \r\ndtm \r\ninspect(dtm)\r\ntdm <- TermDocumentMatrix(docs)   \r\ntdm\r\nfreq <- colSums(as.matrix(dtm))   \r\nlength(freq)   \r\nord <- order(freq)   \r\ndtms <- removeSparseTerms(dtm, 0.1) # This makes a matrix that is 10% empty space, maximum.\r\nfreq[head(ord)]\r\nfreq[tail(ord)]\r\nhead(table(freq), 20)\r\ntail(table(freq), 20)\r\nwf <- data.frame(word=names(freq), freq=freq)   \r\nhead(wf)\r\n# creates plot of word frequency, shows only words that appear at least 3000 times\r\np <- ggplot(subset(wf, freq>3000), aes(word, freq))    \r\np <- p + geom_bar(stat=\"identity\")   \r\np <- p + theme(axis.text.x=element_text(angle=45, hjust=1))   \r\np   \r\n# the code below was repeated for each bank and for each chosen word for each bank (total 16)\r\ndfA = read.csv2(\"BankA.txt\")\r\nidx = sample(1:nrow(dfA),64249)\r\ndfA.entire = dfA\r\ndfA = dfA[idx,]\r\n\r\nbankA.scores = score.sentiment(dfA, pos.words,\r\n                              neg.words, .progress='text')\r\n\r\nbankA.scores$bank = 'BankA'\r\nbankA.scores$code = 'BA'\r\n\r\n\r\nqplot(bankA.scores$score, binwidth = 1)\r\n```\r\n\r\n## Results\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}